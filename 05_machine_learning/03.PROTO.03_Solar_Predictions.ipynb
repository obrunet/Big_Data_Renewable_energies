{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning with Spark \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.options.display.max_columns = 50\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "#from pyspark.sql.functions import lit, col\n",
    "from pyspark.sql.types import DoubleType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what our dataset looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creation of a spark session\n",
    "spk_sess = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"_Project_Spark_App\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# load csv file in a DF and show first lines\n",
    "df = spk_sess.read.csv(\"./solar_generation_by_station.csv\", header=True, sep=\",\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of a dataframe with time step corresponding to measures in our DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_series(start, stop, interval):\n",
    "    \"\"\"\n",
    "    :param start  - lower bound, inclusive\n",
    "    :param stop   - upper bound, exclusive\n",
    "    :interval int - increment interval in seconds\n",
    "    \"\"\"\n",
    "\n",
    "    # Determine start and stops in epoch seconds\n",
    "    start, stop = spk_sess.createDataFrame([(start, stop)], (\"start\", \"stop\")) \\\n",
    "                        .select([col(c).cast(\"timestamp\") \\\n",
    "                        .cast(\"long\") for c in (\"start\", \"stop\")]) \\\n",
    "                        .first()\n",
    "    # Create range with increments and cast to timestamp\n",
    "    return spk_sess.range(start, stop, interval) \\\n",
    "                .select(col(\"id\").cast(\"timestamp\").alias(\"value\"))\n",
    "\n",
    "\n",
    "# credits : https://stackoverflow.com/questions/43141671/sparksql-on-pyspark-how-to-generate-time-series\n",
    "dt_gen = generate_series(\"1986-01-01\", \"2016-01-01\", 60 * 60) # By hour, by day use 60 * 60 * 24\n",
    "\n",
    "# from pyspark.sql.functions import monotonically_increasing_id\n",
    "# The generated ID is guaranteed to be monotonically increasing and unique, but not consecutive :\n",
    "# dt_gen = dt_gen.withColumn(\"index\", monotonically_increasing_id())\n",
    "# an other solution consist in dt_gen = dt_gen.withColumn('index', row_number()) or with zipWithIndex()\n",
    "pandas_df = dt_gen.toPandas()\n",
    "pandas_df['idx'] = pandas_df.index +1\n",
    "dt_gen = spk_sess.createDataFrame(pandas_df)\n",
    "\n",
    "del pandas_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify the 2 DF have the same lenght, then join them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(262968, 262968)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count(), dt_gen.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+-------------------+-------+-------------------+--------------------+\n",
      "|time_step|idx|              value|   AT11|               AT12|                FR10|\n",
      "+---------+---+-------------------+-------+-------------------+--------------------+\n",
      "|        1|  1|1986-01-01 00:00:00|    0.0|                0.0|                 0.0|\n",
      "|        2|  2|1986-01-01 01:00:00|    0.0|                0.0|                 0.0|\n",
      "|        3|  3|1986-01-01 02:00:00|    0.0|                0.0|                 0.0|\n",
      "|        4|  4|1986-01-01 03:00:00|    0.0|                0.0|                 0.0|\n",
      "|        5|  5|1986-01-01 04:00:00|    0.0|                0.0|                 0.0|\n",
      "|        6|  6|1986-01-01 05:00:00|    0.0|                0.0|                 0.0|\n",
      "|        7|  7|1986-01-01 06:00:00|    0.0|                0.0|                 0.0|\n",
      "|        8|  8|1986-01-01 07:00:00|    0.0|                0.0|                 0.0|\n",
      "|        9|  9|1986-01-01 08:00:00|0.13127|0.08148999999999999|                 0.0|\n",
      "|       10| 10|1986-01-01 09:00:00| 0.1259|             0.1032|0.049760000000000006|\n",
      "+---------+---+-------------------+-------+-------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.join(dt_gen, df.time_step == dt_gen.idx)\n",
    "df.select('time_step', 'idx', 'value', 'AT11', 'AT12', 'FR10').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop useless cols\n",
    "df = df.drop('time_step', 'index')\n",
    "\n",
    "# keep only columns relatives to france\n",
    "col_fr = [c for c in df.columns if 'FR' in c]\n",
    "col_fr.append('value')\n",
    "df = df.select(col_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the time_step col\n",
    "df = df.withColumnRenamed(\"value\", \"date_time\")\n",
    "\n",
    "# change cols types\n",
    "for c in df.columns:\n",
    "    if c != 'date_time':\n",
    "        df = df.withColumn(c, df[c].cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There isn't any missing values :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+\n",
      "|FR42|FR61|FR72|FR25|FR26|FR52|FR24|FR21|FR83|FR43|FR23|FR10|FR81|FR63|FR41|FR62|FR30|FR51|FR22|FR53|FR82|FR71|\n",
      "+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+\n",
      "|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|\n",
      "+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#from pyspark.sql.functions import isnan, when, count, col\n",
    "\n",
    "df.select([count(when(isnan(c), c)).alias(c) for c in df.columns if c != 'date_time']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â drop na values if needed / not the case here\n",
    "df = df.na.drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of NaNs, here is a usefull link to [deal with missing values](https://fr.coursera.org/lecture/big-data-machine-learning/handling-missing-values-in-spark-Goh1z). Now, we've to add few columns with the date time infos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-----+-----------+----+\n",
      "|               FR42|          date_time|month|day_of_year|hour|\n",
      "+-------------------+-------------------+-----+-----------+----+\n",
      "|                0.0|1986-01-01 00:00:00|    1|          1|   0|\n",
      "|                0.0|1986-01-01 01:00:00|    1|          1|   1|\n",
      "|                0.0|1986-01-01 02:00:00|    1|          1|   2|\n",
      "|                0.0|1986-01-01 03:00:00|    1|          1|   3|\n",
      "|                0.0|1986-01-01 04:00:00|    1|          1|   4|\n",
      "|                0.0|1986-01-01 05:00:00|    1|          1|   5|\n",
      "|                0.0|1986-01-01 06:00:00|    1|          1|   6|\n",
      "|                0.0|1986-01-01 07:00:00|    1|          1|   7|\n",
      "|            0.05205|1986-01-01 08:00:00|    1|          1|   8|\n",
      "|0.18700999999999998|1986-01-01 09:00:00|    1|          1|   9|\n",
      "|            0.30285|1986-01-01 10:00:00|    1|          1|  10|\n",
      "|            0.21996|1986-01-01 11:00:00|    1|          1|  11|\n",
      "|            0.13234|1986-01-01 12:00:00|    1|          1|  12|\n",
      "|0.07207999999999999|1986-01-01 13:00:00|    1|          1|  13|\n",
      "|            0.05089|1986-01-01 14:00:00|    1|          1|  14|\n",
      "|            0.02337|1986-01-01 15:00:00|    1|          1|  15|\n",
      "|                0.0|1986-01-01 16:00:00|    1|          1|  16|\n",
      "|                0.0|1986-01-01 17:00:00|    1|          1|  17|\n",
      "|                0.0|1986-01-01 18:00:00|    1|          1|  18|\n",
      "|                0.0|1986-01-01 19:00:00|    1|          1|  19|\n",
      "|                0.0|1986-01-01 20:00:00|    1|          1|  20|\n",
      "|                0.0|1986-01-01 21:00:00|    1|          1|  21|\n",
      "|                0.0|1986-01-01 22:00:00|    1|          1|  22|\n",
      "+-------------------+-------------------+-----+-----------+----+\n",
      "only showing top 23 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"year\", year(df.date_time).alias('year')) \\\n",
    "    .withColumn(\"month\", month(df.date_time).alias('month')) \\\n",
    "    .withColumn(\"day_of_year\", dayofyear(df.date_time).alias('day_of_year')) \\\n",
    "    .withColumn(\"hour\", hour(df.date_time).alias('hour'))\n",
    "\n",
    "df.select('FR42', 'date_time', 'month', 'day_of_year', 'hour').orderBy('date_time').show(23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Predictions with various ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE measures the differences between predicted values by the model and the actual values. However, RMSE alone is meaningless until we compare with the actual âMVâ value, such as mean, min and max. After such comparison, our RMSE looks pretty good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-------------------+-------------------+-------------------+-------------------+\n",
      "|summary|               FR10|               FR22|               FR23|               FR24|               FR25|\n",
      "+-------+-------------------+-------------------+-------------------+-------------------+-------------------+\n",
      "|  count|             262968|             262968|             262968|             262968|             262968|\n",
      "|   mean|0.13080652623132855| 0.1259932192129841|0.12627776257947732| 0.1360888294012959|0.12797964170545473|\n",
      "| stddev| 0.2084071774531926|0.20127526900909207|0.20220008711163703|0.20982899870933316|0.20146804261326595|\n",
      "|    min|                0.0|                0.0|                0.0|                0.0|                0.0|\n",
      "|    max|            0.91125| 0.9161299999999999|            0.92315| 0.9179700000000001|            0.92156|\n",
      "+-------+-------------------+-------------------+-------------------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('FR10', 'FR22', 'FR23', 'FR24', 'FR25').describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+-----------+\n",
      "|hour|avg solar efficiency|count(FR10)|\n",
      "+----+--------------------+-----------+\n",
      "|   0|                 0.0|      10957|\n",
      "|   1|                 0.0|      10957|\n",
      "|   2|                 0.0|      10957|\n",
      "|   3|                 0.0|      10957|\n",
      "|   4|3.606552888564386...|      10957|\n",
      "|   5|0.004788690334945695|      10957|\n",
      "|   6|0.029255778954093294|      10957|\n",
      "|   7| 0.10150853974628092|      10957|\n",
      "|   8| 0.20717653281007584|      10957|\n",
      "|   9| 0.31310120105868405|      10957|\n",
      "|  10| 0.37807000730126866|      10957|\n",
      "|  11|  0.4175870010039244|      10957|\n",
      "|  12|  0.4211149110157888|      10957|\n",
      "|  13|  0.3987946728119013|      10957|\n",
      "|  14| 0.34350144656384035|      10957|\n",
      "|  15| 0.27063141735876617|      10957|\n",
      "|  16|  0.1663934708405586|      10957|\n",
      "|  17| 0.06960151775120929|      10957|\n",
      "|  18|0.014985195765264213|      10957|\n",
      "|  19|0.002810180706397738|      10957|\n",
      "|  20|                 0.0|      10957|\n",
      "|  21|                 0.0|      10957|\n",
      "|  22|                 0.0|      10957|\n",
      "|  23|                 0.0|      10957|\n",
      "+----+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"hour\").agg(mean('FR10').alias('avg solar efficiency'), count('FR10')).sort('hour', ascending=True).show(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the 4th hour there is a weird value of 3.60, because efficiency can't be above 1..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â 2.2 Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data for Machine Learning. We need two columns only â features (date time infos) and target (âFR10â):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression, DecisionTreeRegressor, GBTRegressor, RandomForestRegressor, IsotonicRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorAssembler = VectorAssembler(inputCols = ['hour', 'month', 'day_of_year', 'hour'], outputCol = 'features')\n",
    "vect_df = vectorAssembler.transform(df)\n",
    "vect_df = vect_df.select(['features', 'FR10'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into two disctinct sets for training and testing purposes. Here we don't split randomly because this method doesn't make sense for time series : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((209883, 2), (53085, 2))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits = vect_df.randomSplit([0.8, 0.2])\n",
    "train_df = splits[0]\n",
    "test_df = splits[1]\n",
    "(train_df.count(), len(train_df.columns)), (test_df.count(), len(test_df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead we'll keep the last month to test our model, and the rest of the data is used to train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6, 78144), (6, 744))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.select('date_time', 'year', 'month', 'day_of_year', 'hour', 'FR10')\n",
    "#df.write.csv('data_clean.csv')\n",
    "\n",
    "#df.createOrReplaceTempView(\"test\")\n",
    "#df3 = spk_sess.sql(\"select * from test\")\n",
    "#df3.show()\n",
    "\n",
    "df = df.toPandas()\n",
    "df = df[df.year > 2006]\n",
    "train_df, test_df = df[~((df.year == 2015) & (df.month == 12))], df[(df.year == 2015) & (df.month == 12)]\n",
    "train_df, test_df = spk_sess.createDataFrame(train_df), spk_sess.createDataFrame(test_df)\n",
    "(len(train_df.columns), train_df.count()), (len(test_df.columns), test_df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When i try to use df.filter(df.year > 2006) the following error occurs :\n",
    "\n",
    "Py4JJavaError: An error occurred while calling o649.collectToPython.  : java.lang.OutOfMemoryError: GC overhead limit exceeded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 78144), (2, 744))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def vectorize_df(_df):\n",
    "    vectorAssembler = VectorAssembler(inputCols = ['hour', 'month', 'day_of_year'], outputCol = 'features')\n",
    "    return vectorAssembler.transform(_df).select(['features', 'FR10'])\n",
    "\n",
    "train_df, test_df = vectorize_df(train_df), vectorize_df(test_df)\n",
    "(len(train_df.columns), train_df.count()), (len(test_df.columns), test_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------+\n",
      "|       features|   FR10|\n",
      "+---------------+-------+\n",
      "| [11.0,1.0,6.0]|0.04745|\n",
      "|[15.0,1.0,14.0]|0.19483|\n",
      "| [4.0,1.0,24.0]|    0.0|\n",
      "| [2.0,1.0,25.0]|    0.0|\n",
      "|[20.0,2.0,39.0]|    0.0|\n",
      "+---------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.0,0.0,0.0]\n",
      "Intercept: 0.13186472448300593\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression(featuresCol = 'features', labelCol='FR10', maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "lr_model = lr.fit(train_df)\n",
    "print(\"Coefficients: \" + str(lr_model.coefficients))\n",
    "print(\"Intercept: \" + str(lr_model.intercept))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarize the model over the training set and print out some metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.209429\n",
      "r2: 0.000000\n"
     ]
    }
   ],
   "source": [
    "trainingSummary = lr_model.summary\n",
    "print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
    "print(\"r2: %f\" % trainingSummary.r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+-----------------+\n",
      "|         prediction|                FR10|         features|\n",
      "+-------------------+--------------------+-----------------+\n",
      "|0.13186472448300593|0.029639999999999996| [8.0,12.0,336.0]|\n",
      "|0.13186472448300593|             0.39233|[10.0,12.0,339.0]|\n",
      "|0.13186472448300593|                 0.0| [2.0,12.0,347.0]|\n",
      "|0.13186472448300593|                 0.0|[16.0,12.0,350.0]|\n",
      "|0.13186472448300593|                 0.0| [2.0,12.0,360.0]|\n",
      "+-------------------+--------------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "R Squared (R2) on test data = -0.22257\n"
     ]
    }
   ],
   "source": [
    "lr_predictions = lr_model.transform(test_df)\n",
    "lr_predictions.select(\"prediction\",\"FR10\",\"features\").show(5)\n",
    "lr_evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"FR10\",metricName=\"r2\")\n",
    "print(\"R Squared (R2) on test data = %g\" % lr_evaluator.evaluate(lr_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 0.149467\n"
     ]
    }
   ],
   "source": [
    "test_result = lr_model.evaluate(test_df)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % test_result.rootMeanSquaredError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numIterations: 1\n",
      "objectiveHistory: [0.5]\n",
      "+--------------------+\n",
      "|           residuals|\n",
      "+--------------------+\n",
      "|-0.08441472448300594|\n",
      "| 0.06296527551699407|\n",
      "|-0.13186472448300593|\n",
      "|-0.13186472448300593|\n",
      "|-0.13186472448300593|\n",
      "|-0.11619472448300593|\n",
      "|-0.13186472448300593|\n",
      "|-0.13186472448300593|\n",
      "|  0.3843552755169941|\n",
      "|-0.13186472448300593|\n",
      "|-0.13186472448300593|\n",
      "|  0.6594952755169942|\n",
      "|-0.13009472448300594|\n",
      "|-0.13186472448300593|\n",
      "|-0.13186472448300593|\n",
      "|   0.539675275516994|\n",
      "| 0.16819527551699406|\n",
      "|0.027705275516994088|\n",
      "|-0.13186472448300593|\n",
      "| 0.09031527551699409|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"numIterations: %d\" % trainingSummary.totalIterations)\n",
    "print(\"objectiveHistory: %s\" % str(trainingSummary.objectiveHistory))\n",
    "trainingSummary.residuals.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our Linear Regression model to make some predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+-----------------+\n",
      "|         prediction|                FR10|         features|\n",
      "+-------------------+--------------------+-----------------+\n",
      "|0.13186472448300593|0.029639999999999996| [8.0,12.0,336.0]|\n",
      "|0.13186472448300593|             0.39233|[10.0,12.0,339.0]|\n",
      "|0.13186472448300593|                 0.0| [2.0,12.0,347.0]|\n",
      "|0.13186472448300593|                 0.0|[16.0,12.0,350.0]|\n",
      "|0.13186472448300593|                 0.0| [2.0,12.0,360.0]|\n",
      "|0.13186472448300593|                 0.0|[23.0,12.0,336.0]|\n",
      "|0.13186472448300593|                 0.0|[20.0,12.0,345.0]|\n",
      "|0.13186472448300593|             0.01671|[15.0,12.0,347.0]|\n",
      "|0.13186472448300593|                 0.0| [1.0,12.0,353.0]|\n",
      "|0.13186472448300593| 0.12824000000000002|[12.0,12.0,335.0]|\n",
      "|0.13186472448300593|                 0.0| [7.0,12.0,359.0]|\n",
      "|0.13186472448300593| 0.05192000000000001|[15.0,12.0,343.0]|\n",
      "|0.13186472448300593|                 0.0|[20.0,12.0,343.0]|\n",
      "|0.13186472448300593|                 0.0| [0.0,12.0,357.0]|\n",
      "|0.13186472448300593|                 0.0| [3.0,12.0,336.0]|\n",
      "|0.13186472448300593|             0.04358| [9.0,12.0,346.0]|\n",
      "|0.13186472448300593|             0.22576|[14.0,12.0,364.0]|\n",
      "|0.13186472448300593|                 0.0| [6.0,12.0,337.0]|\n",
      "|0.13186472448300593|                 0.0|[20.0,12.0,342.0]|\n",
      "|0.13186472448300593|                 0.0| [0.0,12.0,353.0]|\n",
      "+-------------------+--------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = lr_model.transform(test_df)\n",
    "predictions.select(\"prediction\",\"FR10\",\"features\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Decision tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 0.0839109\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeRegressor(featuresCol ='features', labelCol = 'FR10')\n",
    "dt_model = dt.fit(train_df)\n",
    "\n",
    "dt_predictions = dt_model.transform(test_df)\n",
    "dt_evaluator = RegressionEvaluator(labelCol=\"FR10\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = dt_evaluator.evaluate(dt_predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(3, {0: 0.8302, 1: 0.1066, 2: 0.0632})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_model.featureImportances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Random Forrest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------------+\n",
      "|          prediction|                FR10|         features|\n",
      "+--------------------+--------------------+-----------------+\n",
      "|   0.047394335587558|0.029639999999999996| [8.0,12.0,336.0]|\n",
      "| 0.13750131879665933|             0.39233|[10.0,12.0,339.0]|\n",
      "|0.028248235424898925|                 0.0| [2.0,12.0,347.0]|\n",
      "|0.019594284593185803|                 0.0|[16.0,12.0,350.0]|\n",
      "|0.022353252692110394|                 0.0| [2.0,12.0,360.0]|\n",
      "+--------------------+--------------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(featuresCol = 'features', labelCol = 'FR10')\n",
    "rf_model = rf.fit(train_df)\n",
    "rf_predictions = rf_model.transform(test_df)\n",
    "rf_predictions.select('prediction', 'FR10', 'features').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 0.102336\n"
     ]
    }
   ],
   "source": [
    "rf_evaluator = RegressionEvaluator(labelCol=\"FR10\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = rf_evaluator.evaluate(rf_predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Gradient-boosted tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------------+\n",
      "|          prediction|                FR10|         features|\n",
      "+--------------------+--------------------+-----------------+\n",
      "| 0.07350410135473669|0.029639999999999996| [8.0,12.0,336.0]|\n",
      "|  0.2154570770400125|             0.39233|[10.0,12.0,339.0]|\n",
      "|-0.00126914225566...|                 0.0| [2.0,12.0,347.0]|\n",
      "|-0.00462768737890...|                 0.0|[16.0,12.0,350.0]|\n",
      "|-0.00126914225566...|                 0.0| [2.0,12.0,360.0]|\n",
      "+--------------------+--------------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbt = GBTRegressor(featuresCol = 'features', labelCol = 'FR10', maxIter=10)\n",
    "gbt_model = gbt.fit(train_df)\n",
    "gbt_predictions = gbt_model.transform(test_df)\n",
    "gbt_predictions.select('prediction', 'FR10', 'features').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 0.0810609\n"
     ]
    }
   ],
   "source": [
    "gbt_evaluator = RegressionEvaluator(labelCol=\"FR10\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = gbt_evaluator.evaluate(gbt_predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 Survival regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boundaries in increasing order: [0.0,4.0,4.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,23.0]\n",
      "\n",
      "Predictions associated with the boundaries: [0.0,0.0,0.0001525306813372831,0.0001525306813372831,0.00023999999999999998,0.00043,0.00047000000000000004,0.00053,0.0006,0.00063,0.00067,0.0006900000000000001,0.0007,0.0007099999999999999,0.00075,0.0007599999999999999,0.00081,0.00088,0.0008900000000000001,0.0009199999999999999,0.0009400000000000001,0.00095,0.0009599999999999999,0.00098,0.00099,0.00101,0.00103,0.00105,0.00107,0.00112,0.00114,0.00115,0.0012900000000000001,0.00132,0.00134,0.00135,0.00137,0.0013800000000000002,0.00139,0.0014,0.00141,0.00147,0.00151,0.0015300000000000001,0.00155,0.00156,0.00159,0.0016,0.00162,0.0016300000000000002,0.00165,0.0016699999999999998,0.00172,0.00173,0.00175,0.0017699999999999999,0.00187,0.0018899999999999998,0.00195,0.00198,0.00199,0.002,0.00202,0.0020399999999999997,0.00209,0.00212,0.00214,0.00215,0.00217,0.00218,0.0022,0.00221,0.00225,0.00235,0.00237,0.0024,0.00242,0.00245,0.00248,0.00256,0.00257,0.0026,0.00266,0.0027300000000000002,0.00274,0.00275,0.00277,0.00278,0.00281,0.00282,0.00285,0.0029100000000000003,0.00292,0.00298,0.00299,0.0030399999999999997,0.0030800000000000003,0.0031,0.00312,0.0031899999999999997,0.00322,0.00323,0.0032600000000000003,0.0032700000000000003,0.0034,0.0034100000000000003,0.00344,0.0034700000000000004,0.00352,0.00355,0.0036899999999999997,0.0037600000000000003,0.0038299999999999996,0.00387,0.0038799999999999998,0.00389,0.00391,0.00392,0.0039299999999999995,0.00394,0.00395,0.00396,0.004,0.00404,0.004070000000000001,0.00413,0.0042,0.004220000000000001,0.004229999999999999,0.00426,0.00428,0.004370000000000001,0.00443,0.00445,0.00447,0.0045,0.00451,0.00454,0.00455,0.00456,0.00465,0.0046700000000000005,0.0047,0.00471,0.00473,0.00476,0.00479,0.00484,0.0049299999999999995,0.00496,0.00499,0.00502,0.00503,0.00505,0.00506,0.00509,0.00519,0.0052,0.005229999999999999,0.00524,0.00532,0.00533,0.00536,0.0054,0.00545,0.00547,0.005520000000000001,0.00556,0.00558,0.00564,0.00565,0.00566,0.0056700000000000006,0.00573,0.00575,0.0057799999999999995,0.00584,0.00588,0.0059700000000000005,0.00602,0.0061,0.00614,0.00615,0.00618,0.00629,0.006370000000000001,0.006490000000000001,0.0065,0.006520000000000001,0.00656,0.006640000000000001,0.00665,0.00673,0.0067599999999999995,0.00677,0.006790000000000001,0.00686,0.0069,0.0069099999999999995,0.00698,0.00701,0.00702,0.00705,0.007109999999999999,0.0071400000000000005,0.00715,0.00716,0.00717,0.00718,0.007240000000000001,0.00733,0.007370000000000001,0.007390000000000001,0.0074,0.007490000000000001,0.0075,0.007529999999999999,0.007559999999999999,0.00761,0.00763,0.007640000000000001,0.007659999999999999,0.00772,0.00773,0.0077599999999999995,0.00777,0.0078,0.00788,0.007890000000000001,0.00793,0.007940000000000001,0.00796,0.008140000000000001,0.00815,0.008159999999999999,0.00817,0.00821,0.00827,0.00831,0.0084,0.00842,0.00843,0.008440000000000001,0.00847,0.008490000000000001,0.00857,0.008620000000000001,0.00865,0.0087,0.008709999999999999,0.00873,0.00882,0.008842639000805813,0.008842639000805813,0.008879999999999999,0.00902,0.009040000000000001,0.00907,0.00923,0.009470000000000001,0.0095,0.009729999999999999,0.00988,0.01011,0.01015,0.0103,0.01039,0.01045,0.01055,0.01063,0.010709999999999999,0.01073,0.01096,0.01102,0.01112,0.01115,0.01116,0.011590000000000001,0.01166,0.01178,0.01183,0.011909999999999999,0.011940000000000001,0.01211,0.012209999999999999,0.01222,0.01236,0.01248,0.01253,0.01268,0.0127,0.012709999999999999,0.01277,0.012819999999999998,0.01285,0.01289,0.01291,0.013009999999999999,0.013080000000000001,0.013090000000000001,0.0131,0.01315,0.01316,0.01318,0.01321,0.013590000000000001,0.013630000000000001,0.01366,0.013669999999999998,0.01375,0.01379,0.013819999999999999,0.013940000000000001,0.0142,0.014240000000000001,0.01427,0.0144,0.01441,0.0147,0.014719999999999999,0.015119999999999998,0.01522,0.015280000000000002,0.015319999999999999,0.015340000000000001,0.015380000000000001,0.01544,0.01556,0.015719999999999998,0.01587,0.01602,0.01608,0.01612,0.01624,0.016280000000000003,0.01634,0.01645,0.01646,0.01659,0.016669999999999997,0.01677,0.01683,0.016890000000000002,0.0169,0.017,0.01706,0.017230000000000002,0.017240000000000002,0.01739,0.01771,0.017740000000000002,0.01779,0.01784,0.01791,0.01793,0.01807,0.01811,0.01813,0.01818,0.01825,0.01835,0.018369999999999997,0.01851,0.01866,0.01888,0.01896,0.019030000000000002,0.01913,0.01929,0.01942,0.01944,0.01951,0.019540000000000002,0.01965,0.01984,0.01996,0.01999,0.02002,0.02014,0.02017,0.02049,0.02051,0.02052,0.02056,0.02058,0.02069,0.02072,0.02083,0.02085,0.020909999999999998,0.020919999999999998,0.02094,0.02102,0.0211,0.021269999999999997,0.02129,0.02134,0.02168,0.021840000000000002,0.02191,0.02201,0.022109999999999998,0.02222,0.022269999999999998,0.0223,0.02232,0.02244,0.02264,0.02267,0.022690000000000002,0.02276,0.0229,0.022930000000000002,0.02301,0.02327,0.02349,0.023540000000000002,0.02359,0.02367,0.0237,0.02371,0.02377,0.02384,0.02387,0.02392,0.02393,0.023969999999999998,0.02399,0.02409,0.02416,0.02418,0.02419,0.02435,0.02446,0.02449,0.02453,0.024569999999999998,0.024659999999999998,0.024669999999999997,0.02469,0.02479,0.02484,0.024909999999999998,0.024980000000000002,0.024990000000000002,0.02516,0.025240000000000002,0.025259999999999998,0.025330000000000002,0.02539,0.025509999999999998,0.02574,0.02576,0.025910000000000002,0.02599,0.026060000000000003,0.026080000000000002,0.0261,0.02615,0.02642,0.026639999999999997,0.026719999999999997,0.02675,0.02685,0.026889999999999997,0.0269,0.026930000000000003,0.02694,0.02695,0.02696,0.02719,0.02723,0.02743,0.02744,0.027610000000000003,0.027630000000000002,0.027780000000000003,0.027839999999999997,0.02797,0.02798,0.02808,0.028110000000000003,0.02816,0.02835,0.02841,0.028439999999999997,0.028460000000000003,0.02852,0.02858,0.028739999999999998,0.02877,0.0288,0.02882,0.02883,0.02885,0.028860000000000004,0.02891,0.028939999999999997,0.028999999999999998,0.02912,0.02913,0.02922,0.02937,0.029410000000000002,0.029519999999999998,0.02953,0.029560000000000003,0.02962,0.02995,0.030239999999999996,0.03027,0.03028,0.03035,0.030510000000000002,0.030560000000000004,0.030719999999999997,0.03073,0.03082,0.03112,0.031310000000000004,0.03135,0.031389999999999994,0.03149,0.03157,0.031810000000000005,0.03186,0.03193,0.03229,0.03232,0.03254,0.03266,0.03269,0.032760000000000004,0.032780000000000004,0.033010000000000005,0.03317,0.03321,0.03329,0.0333,0.03342,0.033460000000000004,0.03349,0.033589999999999995,0.0336,0.03367,0.033760000000000005,0.03377,0.033889999999999997,0.03392,0.03411,0.03412,0.03422,0.034319999999999996,0.03435,0.03436,0.03439,0.03465,0.03469,0.034730000000000004,0.03478,0.03485,0.03486,0.03492,0.03493,0.03495,0.035019999999999996,0.035039999999999995,0.03507,0.03512,0.03513,0.03528,0.03532,0.03537,0.03544,0.03553,0.03561,0.03572,0.03574,0.03585,0.03595,0.036039999999999996,0.03606,0.03607,0.03612,0.03623,0.03634,0.0364,0.036410000000000005,0.03642,0.03655,0.036739999999999995,0.03677,0.03681,0.03715,0.03725,0.03726,0.03729,0.03732,0.03737,0.03741,0.03745,0.03766,0.037989999999999996,0.03803,0.03814,0.03821,0.03825,0.03835,0.03837,0.038380000000000004,0.03852,0.038560000000000004,0.038610000000000005,0.03864,0.03888,0.038939999999999995,0.03896,0.03904,0.03916,0.03918,0.03927,0.039389999999999994,0.0394,0.039439999999999996,0.03948,0.03951,0.039580000000000004,0.0396,0.0397,0.03998,0.040010000000000004,0.04007,0.0402,0.04023,0.0403,0.04032,0.04033,0.040369999999999996,0.04038,0.04082,0.04083,0.04088,0.040889999999999996,0.0409,0.04091,0.04096,0.04102,0.04108,0.04112,0.04116,0.04131,0.041319999999999996,0.04143,0.04144,0.04149,0.04154,0.041639999999999996,0.04165,0.04169,0.041710000000000004,0.04192,0.04222,0.04225,0.04231,0.04243,0.042480000000000004,0.04252,0.04256,0.04258,0.042710000000000005,0.042789999999999995,0.0428,0.04285,0.04295,0.04303,0.04315,0.0433,0.04343,0.043460000000000006,0.04356,0.04357,0.04367,0.04383,0.04396,0.04397,0.043989999999999994,0.04406,0.04437,0.044489999999999995,0.04455,0.04459,0.04476,0.04477,0.0448,0.04484,0.04493,0.044989999999999995,0.04502,0.04507,0.0451,0.04523,0.045239999999999995,0.04537,0.04554,0.04555,0.04565,0.04576,0.04596,0.045989999999999996,0.04602,0.04605,0.04607,0.04609,0.046360000000000005,0.0465,0.04663,0.04664047939444915,0.04664047939444915,0.04671,0.04677,0.04687,0.04688,0.04691,0.04721,0.04726,0.047369999999999995,0.047580000000000004,0.047619999999999996,0.04766,0.04775,0.047830000000000004,0.04843,0.04861,0.04873,0.048780000000000004,0.04883,0.0489,0.04899,0.04904,0.049339999999999995,0.049389999999999996,0.04992,0.05057,0.05058,0.05068,0.05074,0.05095,0.05108,0.051289999999999995,0.05134,0.05145,0.05149,0.051739999999999994,0.05192000000000001,0.05197,0.05212000000000001,0.05214,0.052289999999999996,0.05234,0.05239,0.05242,0.05292,0.05301,0.05304,0.05319,0.05347999999999999,0.053689999999999995,0.053739999999999996,0.053779999999999994,0.05393,0.05397999999999999,0.05405,0.05416,0.05421,0.054229999999999993,0.05442999999999999,0.054479999999999994,0.05462,0.05513,0.055220000000000005,0.055470000000000005,0.05554,0.05585,0.0564,0.0567,0.05679,0.05694,0.05703,0.0575,0.05777,0.05795,0.05801,0.05807999999999999,0.058179999999999996,0.05826,0.05847,0.05856,0.05869,0.058839999999999996,0.05885,0.058929999999999996,0.05895,0.05905,0.059070000000000004,0.059129999999999995,0.05914,0.05944,0.05996,0.06006,0.06021,0.06034,0.06039,0.06042,0.06045,0.06047,0.060579999999999995,0.06072999999999999,0.06081,0.060820000000000006,0.06088,0.06091,0.060989999999999996,0.0611,0.06117,0.0612,0.06162,0.061770000000000005,0.061939999999999995,0.062020000000000006,0.062060000000000004,0.062229999999999994,0.06239,0.062439999999999996,0.0626,0.06276,0.06297,0.06319,0.06324,0.06329,0.06344,0.06357,0.06362999999999999,0.06379,0.06385,0.06393,0.064,0.06404,0.06405,0.06417,0.06446,0.06448999999999999,0.06457,0.06498999999999999,0.06529,0.06548,0.06558,0.06581000000000001,0.06606000000000001,0.06616,0.06626,0.06641,0.06663999999999999,0.06665,0.06667000000000001,0.06667999999999999,0.06692999999999999,0.06699,0.067,0.06704,0.06706000000000001,0.06717999999999999,0.06724,0.06726,0.06729,0.06736,0.06738,0.06772,0.06792999999999999,0.0682,0.06867000000000001,0.06872,0.06904,0.06931,0.06932,0.06932999999999999,0.0695,0.06951,0.06955,0.06956,0.06977,0.06992000000000001,0.07015,0.07023,0.07034,0.07045,0.07061,0.07082999999999999,0.07084,0.07092999999999999,0.07094,0.07099,0.07103,0.07113,0.07117000000000001,0.07132000000000001,0.07146,0.07152,0.07157999999999999,0.07176,0.07185,0.07194,0.07196,0.07221,0.07232000000000001,0.07253,0.07272,0.07275,0.0728,0.07293999999999999,0.07307000000000001,0.0731,0.07315,0.07343999999999999,0.07364,0.07367,0.0737,0.07372999999999999,0.07400000000000001,0.07405,0.07427,0.07431,0.07462,0.07493999999999999,0.07497999999999999,0.0751,0.07558,0.07559,0.07562,0.0757,0.07574,0.07575,0.07576000000000001,0.0758,0.07583,0.07611,0.07637999999999999,0.07652,0.07655,0.0766,0.07665,0.07687999999999999,0.07689,0.07705,0.0771,0.07716,0.07727,0.07774,0.0781,0.07818,0.07821,0.07869,0.07872,0.07873,0.07874,0.07895,0.079,0.07909,0.07911,0.07926,0.07932,0.07942,0.07946,0.0795,0.0796,0.07965,0.07976,0.07986,0.07987000000000001,0.07989,0.07996,0.07998,0.08004,0.08045,0.08051,0.08052000000000001,0.08065,0.08077999999999999,0.08079,0.08089,0.08098,0.08107,0.0811,0.08114,0.08115,0.08146,0.08165,0.08172,0.08229,0.08233,0.08235,0.08266,0.08269,0.08282,0.08288,0.08298,0.08302999999999999,0.0831,0.08333,0.08334,0.08374,0.08382,0.08417999999999999,0.08429,0.08434,0.08444,0.08445,0.08457,0.08471000000000001,0.08478,0.085,0.08501,0.08509,0.08523,0.08532000000000001,0.08555,0.08557000000000001,0.08598,0.08627,0.08628999999999999,0.0863,0.08645,0.08656,0.08659,0.08663,0.08667000000000001,0.08673,0.08686,0.08705,0.08707000000000001,0.08744,0.08748,0.08755,0.08809,0.08821,0.08826,0.08827,0.08849,0.08851,0.08853,0.08856,0.08862,0.08881,0.08902,0.08906,0.08934,0.08961000000000001,0.08974,0.08991,0.09,0.09015,0.09021,0.09049,0.09062,0.09072000000000001,0.09078,0.09087999999999999,0.09137,0.09167,0.09175,0.09181,0.09214,0.09217,0.09218,0.09249,0.09279,0.09292,0.09296,0.09325,0.09327,0.09342,0.09355,0.09382,0.09383,0.09407,0.09451,0.09455,0.0946,0.09472,0.09475,0.0948,0.09496,0.0952,0.09527999999999999,0.09547,0.09562999999999999,0.09573,0.09573999999999999,0.09582,0.09587999999999999,0.09602999999999999,0.09611,0.09616,0.09625,0.09629,0.09666,0.09667,0.09688,0.09715,0.09731000000000001,0.09764,0.09798,0.098,0.09802999999999999,0.09817000000000001,0.09819,0.09833,0.09838,0.09838999999999999,0.09841,0.09848,0.09852999999999999,0.09854,0.099,0.09932,0.09938999999999999,0.09949,0.09962,0.09969,0.09979,0.10013999999999999,0.10024,0.10052,0.10064,0.10069,0.1007,0.10074,0.10079,0.10092999999999999,0.10121000000000001,0.10149,0.10161,0.10166,0.10209,0.1021,0.10237,0.10238,0.10268,0.10287,0.10295,0.10296,0.10299000000000001,0.10355,0.10362,0.10365999999999999,0.10378,0.10385,0.10400000000000001,0.10405999999999999,0.10427,0.10428,0.10457999999999999,0.10471,0.10475,0.10485,0.10487,0.10490999999999999,0.10522999999999999,0.10561,0.10585,0.10607,0.10622999999999999,0.10645999999999999,0.10655,0.10662,0.10665999999999999,0.10695999999999999,0.10730999999999999,0.10749,0.10765999999999999,0.10767,0.10812999999999999,0.10830999999999999,0.10901,0.10914000000000001,0.10945999999999999,0.10976,0.10984000000000001,0.10987999999999999,0.11009000000000001,0.11059000000000001,0.1111,0.11112999999999999,0.11122,0.11130999999999999,0.11137000000000001,0.11141,0.11163,0.1117,0.11184000000000001,0.11205,0.11208,0.11218,0.11220999999999999,0.1123,0.11285999999999999,0.11291,0.11312,0.11316,0.11327000000000001,0.11337,0.11362,0.11363,0.11395999999999999,0.11409000000000001,0.11425999999999999,0.11431,0.11437,0.11448,0.1147,0.11503,0.11508,0.11522,0.11528,0.11547,0.11575,0.11581,0.11595,0.11609000000000001,0.11619000000000002,0.11642999999999999,0.11649000000000001,0.11652,0.11653,0.11655,0.11675,0.11675999999999999,0.11678,0.11685999999999999,0.11692000000000001,0.11702,0.11704,0.11724000000000001,0.11739000000000001,0.11753,0.1176,0.11803,0.11805,0.11827,0.11849000000000001,0.11850999999999999,0.11863,0.11865999999999999,0.11892,0.11905,0.11915,0.11919,0.11925,0.11928,0.11932000000000001,0.11942,0.11955,0.11972999999999999,0.11980999999999999,0.11994,0.11997000000000001,0.12004000000000001,0.12007999999999999,0.12019,0.12027,0.1204,0.12044,0.12055,0.12070999999999998,0.12077,0.1209,0.12109,0.1214,0.12140999999999999,0.12161,0.12167,0.12211,0.12236,0.12245999999999999,0.12272000000000001,0.12297999999999999,0.12299000000000002,0.12304000000000001,0.12319000000000001,0.12322999999999999,0.12330999999999999,0.12345,0.12354000000000001,0.12380999999999999,0.12453,0.12475,0.12523,0.1253,0.12567,0.12589,0.12611,0.12639,0.12655,0.12672,0.12679,0.12685,0.12712,0.12722999999999998,0.12747,0.12750999999999998,0.12758,0.12791,0.12808,0.12814,0.12824000000000002,0.12837,0.12839,0.12854000000000002,0.12897,0.129,0.12907000000000002,0.1293,0.13009,0.13026,0.13036,0.13041,0.13078,0.13082,0.13129000000000002,0.13135,0.13139,0.13161,0.13172999999999999,0.13195,0.13212000000000002,0.13218,0.13227,0.13235999999999998,0.13244,0.13258,0.1327,0.13275,0.13279000000000002,0.1329,0.13323,0.13326,0.13327,0.13333,0.13345,0.13355,0.13359000000000001,0.13397,0.13405999999999998,0.13416,0.13423,0.1344,0.1346,0.13479000000000002,0.13547,0.13571,0.13584000000000002,0.13592,0.13597,0.13602,0.1363,0.13652999999999998,0.13655,0.13659000000000002,0.13666,0.13668,0.13695,0.13721,0.1374,0.13766,0.13777,0.13793,0.13801,0.1381,0.13810999999999998,0.13827,0.13833,0.1384,0.13882,0.1389,0.13892000000000002,0.13912,0.13915999999999998,0.13923,0.13937,0.13942000000000002,0.13951,0.13975,0.13978,0.14017000000000002,0.14022,0.14046,0.1405,0.14051,0.14052,0.14072,0.14076,0.14077,0.14118,0.14140999999999998,0.1415,0.14157999999999998,0.1416,0.14176,0.14179,0.14198,0.14207999999999998,0.14221,0.14263,0.14278,0.14281,0.14300000000000002,0.14321,0.14362,0.14374,0.14390999999999998,0.14394,0.14400000000000002,0.14431,0.14432,0.14461,0.14465,0.14470999999999998,0.14492,0.14503,0.14509,0.14518,0.14522000000000002,0.14554,0.14564000000000002,0.14572000000000002,0.14587999999999998,0.1459,0.14615999999999998,0.14618,0.14632,0.14662,0.14662999999999998,0.14665,0.14667,0.1467,0.1469,0.14695,0.14717,0.14765999999999999,0.14836,0.14839000000000002,0.14845999999999998,0.14858,0.14861,0.14889000000000002,0.14903,0.14906,0.14909,0.14919000000000002,0.1492,0.14947,0.14957,0.14969000000000002,0.14989,0.15,0.1508,0.1508197915027535,0.1508197915027535,0.15082,0.151,0.15108,0.15149,0.1515,0.15187,0.15198,0.15212,0.15214,0.15222,0.15224000000000001,0.15225999999999998,0.15241,0.15245,0.1525,0.15259,0.15281,0.15303,0.15312,0.15319000000000002,0.15323,0.15327000000000002,0.15355,0.15359,0.15385,0.15399000000000002,0.15403,0.15408,0.1541,0.15444000000000002,0.15452,0.15466,0.15517999999999998,0.15533,0.15542999999999998,0.15558,0.1558,0.15594,0.15645,0.15653,0.1567,0.15691,0.15699000000000002,0.15721,0.15750999999999998,0.15757000000000002,0.15817,0.15819,0.15832000000000002,0.15869,0.15896,0.15904000000000001,0.15912,0.15936,0.15952,0.15992,0.15993,0.15996,0.16038,0.1604,0.16053,0.16075,0.16079000000000002,0.16085,0.16091,0.16128,0.16129000000000002,0.16132,0.16199000000000002,0.16215,0.1627,0.16277,0.16279000000000002,0.16285,0.16288,0.1629,0.16337000000000002,0.16355,0.16367,0.16376,0.16383,0.16384,0.1639,0.16458,0.16477,0.16482,0.16502,0.1651,0.16519,0.16527,0.16546,0.16549,0.16580999999999999,0.1659,0.16594,0.16618,0.16642,0.16655,0.16672,0.16675,0.16688,0.1669,0.16697,0.16701,0.16726,0.16731,0.16733,0.16751,0.16752999999999998,0.16758,0.16766,0.16791,0.1682,0.16827,0.16839,0.16868,0.16895,0.16910999999999998,0.16939,0.1695,0.16978,0.16982,0.1699,0.17003,0.17043,0.17063,0.17098,0.17121,0.17129,0.17132999999999998,0.17144,0.17151,0.17187,0.17227,0.17231,0.17242000000000002,0.1726,0.17264000000000002,0.17276,0.17356,0.1736,0.1737,0.17378,0.17379,0.17382,0.17396,0.17402,0.1743,0.17431,0.17479,0.17481,0.17486,0.1752,0.17539000000000002,0.17553,0.17575,0.17604,0.17606,0.17644,0.17649,0.17668,0.17681,0.17747000000000002,0.17770999999999998,0.17789000000000002,0.1779,0.17862999999999998,0.17915999999999999,0.17918,0.1792,0.17927,0.17945,0.17949,0.17983,0.18,0.18031,0.18059,0.18132,0.18134,0.18161,0.18168,0.18207,0.18211,0.18255,0.18267,0.18306,0.18319000000000002,0.18323,0.18350999999999998,0.18362,0.18381,0.18450999999999998,0.18454,0.18541,0.18548,0.18597,0.18655,0.18671,0.18684,0.18700999999999998,0.18717,0.18742,0.18755,0.1876,0.18777,0.18787,0.18838,0.18883,0.18902,0.18904,0.1891,0.18925,0.18986,0.18989,0.18996,0.19059,0.1907,0.19071,0.19101931436142883,0.19101931436142883]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Trains an isotonic regression model.\n",
    "iso = IsotonicRegression(featuresCol = 'features', labelCol = 'FR10')\n",
    "\n",
    "iso_model = iso.fit(train_df)\n",
    "print(\"Boundaries in increasing order: %s\\n\" % str(iso_model.boundaries))\n",
    "print(\"Predictions associated with the boundaries: %s\\n\" % str(iso_model.predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+-----------------+\n",
      "|         prediction|                FR10|         features|\n",
      "+-------------------+--------------------+-----------------+\n",
      "|            0.15222|0.029639999999999996| [8.0,12.0,336.0]|\n",
      "|0.19101931436142883|             0.39233|[10.0,12.0,339.0]|\n",
      "|                0.0|                 0.0| [2.0,12.0,347.0]|\n",
      "|0.19101931436142883|                 0.0|[16.0,12.0,350.0]|\n",
      "|                0.0|                 0.0| [2.0,12.0,360.0]|\n",
      "+-------------------+--------------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Makes predictions.\n",
    "iso_predictions = iso_model.transform(test_df)\n",
    "iso_predictions.select('prediction', 'FR10', 'features').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 0.144906\n"
     ]
    }
   ],
   "source": [
    "iso_evaluator = RegressionEvaluator(labelCol=\"FR10\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = iso_evaluator.evaluate(iso_predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Conclusions\n",
    "\n",
    "Root Mean Squared Errors (RMSE) on test data \n",
    "- linear regression : 0.149\n",
    "- decision tree regression : 0.084\n",
    "- random forrest regression : 0.102\n",
    "- survival regression : 0.145"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
